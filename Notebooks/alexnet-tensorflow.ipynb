{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Installing (updating) the following libraries for your Sagemaker\n",
    "instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AlexNet - TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T19:20:31.459773Z",
     "start_time": "2021-03-21T19:20:29.566942Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from d2l import tensorflow as d2l\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T19:20:31.468039Z",
     "start_time": "2021-03-21T19:20:31.461619Z"
    },
    "origin_pos": 3,
    "slideshow": {
     "slide_type": "slide"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def net():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4,\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "        tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We construct a single-channel data example with both height and width of 224 to observe the output shape of each layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T19:20:34.374660Z",
     "start_time": "2021-03-21T19:20:31.469965Z"
    },
    "origin_pos": 7,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D Output shape:\t (1, 54, 54, 96)\n",
      "MaxPooling2D Output shape:\t (1, 26, 26, 96)\n",
      "Conv2D Output shape:\t (1, 26, 26, 256)\n",
      "MaxPooling2D Output shape:\t (1, 12, 12, 256)\n",
      "Conv2D Output shape:\t (1, 12, 12, 384)\n",
      "Conv2D Output shape:\t (1, 12, 12, 384)\n",
      "Conv2D Output shape:\t (1, 12, 12, 256)\n",
      "MaxPooling2D Output shape:\t (1, 5, 5, 256)\n",
      "Flatten Output shape:\t (1, 6400)\n",
      "Dense Output shape:\t (1, 4096)\n",
      "Dropout Output shape:\t (1, 4096)\n",
      "Dense Output shape:\t (1, 4096)\n",
      "Dropout Output shape:\t (1, 4096)\n",
      "Dense Output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1, 224, 224, 1))\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'Output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Although AlexNet is trained on ImageNet in the paper, we use Fashion-MNIST here\n",
    "since training an ImageNet model to convergence could take hours or days\n",
    "even on a modern GPU.\n",
    "One of the problems with applying AlexNet directly on Fashion-MNIST\n",
    "is that its images have lower resolution ($28 \\times 28$ pixels)\n",
    "than ImageNet images.\n",
    "To make things work, we upsample them to $224 \\times 224$\n",
    "(generally not a smart practice,\n",
    "but we do it here to be faithful to the AlexNet architecture).\n",
    "We perform this resizing with the `resize` argument in the `d2l.load_data_fashion_mnist` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T19:20:35.230689Z",
     "start_time": "2021-03-21T19:20:34.376631Z"
    },
    "origin_pos": 9,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "Now, we can start training AlexNet.\n",
    "Compared with LeNet in :numref:`sec_lenet`,\n",
    "the main change here is the use of a smaller learning rate\n",
    "and much slower training due to the deeper and wider network,\n",
    "the higher image resolution, and the more costly convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T19:20:29.496Z"
    },
    "origin_pos": 11,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.327, train acc 0.881, test acc 0.884\n",
      "4397.7 examples/sec on /GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1d15acd310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 10\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 15,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "[Q&A for this notebook](https://discuss.d2l.ai/t/276)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
