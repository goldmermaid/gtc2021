{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spread-secretariat",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### GTC2021 Tutorial S31692\n",
    "----\n",
    "\n",
    "# Dive into Deep Learning:\n",
    "### Code Side-by-Side with MXNet, PyTorch & TensorFlow\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "    Rachel Hu \n",
    "\n",
    "    Applied Scientist @ AWS AI\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-growth",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MXNet, PyTorch or TensorFlow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-period",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Deep learning is transforming the world nowadays. Kudos to the continuous advancement of Nvidia powered GPUs and CUDA architecture, parallel model training becomes more realistic and easy to setup. As a result, researchers and practioners may dive deep and focus on model exploration.\n",
    "\n",
    "Around the GPU ecosystem, popular deep learning frameworks with GPU support have been released and iteratively updated. From the earlier version of theano and Caffeine, to now the three most widely used ones: MXNet, PyTorch and TensorFlow. Although these frameworks have similar user interface and similar functionalities, the inherent differences of their designs, architectures, and implementations may lead to a potential variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-apartment",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"img/mxnet_pytorch_tf_transp.png\" alt=\"Drawing\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-tiffany",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Which framework shall I pick?\n",
    "\n",
    "\n",
    "<img src=\"img/dl_comparison.png\" alt=\"Drawing\" style=\"width: 1400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-tonight",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "You may curious \"which framework shall I pick for my model?\" Well, the answer is \"it depends\"... \n",
    "Different DL frameworks have different speed acceleration over different network architectures. For example, sometimes you may find framework A is quicker than framework B on batch size equals to 32, but framwork A is slower than the others on batch size equals to 64. Besides, different DL frameworks also have different sparse matrix optimization, different mixed-precision calculation, etc. \n",
    "\n",
    "So the point i want to make here is that -- \"You may pick *all*.\" You may find tons of blogs online, deliberately compare the 3 frameworks, but their results are sometimes counterpart with each other. What is more, as DL a vigorous and booming field that grows rapidly, the comparison results from last year may not hold as is this year. \n",
    "\n",
    "So what shall we do? Shall we stop comparing but try all of them? \n",
    "\n",
    "It may not be a satisfied answer if you may only familiar with one of the three frameworks. But today, I am brining you a magic key to quickly adapt the transformations between all of the 3 frameworks. And you will find yourself be master at all the three frameworks quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-fence",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "You may pick *all*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-cooperation",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"img/d2l_frontpage.png\" alt=\"Drawing\" style=\"width: 1400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-alexandria",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This key is called [Dive into Deep Learning](https://d2l.ai/), a unified deep learning resource to fulfill the strong wishes of simpler but more practical deep learning materials.\n",
    "\n",
    "\n",
    "- Adopt the 3 most popular deep leraning frameworks: MXNet, PyTorch and TensorFlow;\n",
    "- Offer both theory and runnable code side-by-side, showing readers how to solve problems in practice, such as CV, NLP and Recommendation system;\n",
    "- Allow for rapid updates, and keep pace with the SOTA research: we are continuously adding more chapters such Graph Neural Network (GNN), AutoML, etc.;\n",
    "- host a forum for interactive discussions of technical details;\n",
    "- Be freely available for everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-disco",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code Side-by-Side with MXNet, PyTorch & TensorFlow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-connection",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "### GPU Fundamentals\n",
    "\n",
    "- [Installations with CUDA](https://d2l.ai/chapter_installation/index.html)\n",
    "- [Basic Operations on GPUs](https://nbviewer.jupyter.org/format/slides/github/mli/d2l-1day-notebooks/blob/master/notebooks-2/1-use-gpu.ipynb#/)\n",
    "- [Hardware for deep learning](https://d2l.ai/chapter_computational-performance/hardware.html#gpus-and-other-accelerators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-shade",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning Fundamentals\n",
    "\n",
    "Here are a few concepts that will be the prerequistes for this lecture. \n",
    "\n",
    "<br>\n",
    "\n",
    "| Title                               |      |      |\n",
    "| ------------------------------ | ---- | ---- |\n",
    "| Data Manipulation with Ndarray | [D2L Book](https://d2l.ai/chapter_preliminaries/ndarray.html) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/mli/d2l-1day-notebooks/blob/master/notebooks-1/1-ndarray.ipynb#/) |\n",
    "| Multilayer Perceptron (MLP) | [D2L Book](https://d2l.ai/chapter_multilayer-perceptrons/mlp.html) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/mli/d2l-1day-notebooks/blob/master/notebooks-1/9-mlp-gluon.ipynb#/) |\n",
    "| Softmax Regression | [D2L Book](https://d2l.ai/chapter_linear-networks/softmax-regression.html) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/mli/d2l-1day-notebooks/blob/master/notebooks-1/7-softmax-regression-gluon.ipynb#/) |\n",
    "| Fundamental of Convolutional Neural Networks | [D2L Book](https://d2l.ai/chapter_convolutional-neural-networks/index.html) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2020/blob/master/Notebooks/convolutions.ipynb) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-mumbai",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Syllabus\n",
    "\n",
    "In this training, we are applying AlexNet directly on Fashion-MNIST dataset, with 3 frameworks side-by-side.\n",
    "\n",
    "<br>\n",
    "\n",
    "| Topics |  |  |\n",
    "| --- | --- | --- |\n",
    "| AlexNet Overview | [D2L Book](https://d2l.ai/chapter_convolutional-modern/alexnet.html#alexnet) | \n",
    "| AlexNet (PyTorch) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/notebooks/alexnet-torch.ipynb) | [Nbviewer](notebooks/alexnet-torch.slides.html)|\n",
    "| AlexNet (MXNet) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/Notebooks/Alexnet-mxnet.ipynb) | [Nbviewer](notebooks/alexnet-mxnet.slides.html)|\n",
    "| AlexNet (TensorFlow) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/notebooks/alexnet-tensorflow.ipynb) | [Nbviewer](notebooks/alexnet-tensorflow.slides.html)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-christianity",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## AlexNet\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"img/alexnet.png\" alt=\"Drawing\" style=\"width: 1600px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-bible",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "AlexNet, which employed an 8-layer CNN,\n",
    "won the ImageNet Large Scale Visual Recognition Challenge 2012\n",
    "by a phenomenally large margin.\n",
    "This network showed, for the first time,\n",
    "that the features obtained by learning can transcend manually-designed features, breaking the previous paradigm in computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-museum",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The architecture of AlexNet is illustrated below.\n",
    "\n",
    "<center><img src=\"img/alexnetonly.svg\" alt=\"Drawing\" style=\"width: 150px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-joshua",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coding side-by-side\n",
    "\n",
    "<br>\n",
    "\n",
    "| Topics |  |  |\n",
    "| --- | --- | --- |\n",
    "| AlexNet Overview | [D2L Book](https://d2l.ai/chapter_convolutional-modern/alexnet.html#alexnet) | \n",
    "| AlexNet (PyTorch) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/notebooks/alexnet-torch.ipynb) | [Nbviewer](notebooks/alexnet-torch.slides.html)|\n",
    "| AlexNet (MXNet) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/Notebooks/Alexnet-mxnet.ipynb) | [Nbviewer](notebooks/alexnet-mxnet.slides.html)|\n",
    "| AlexNet (TensorFlow) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/notebooks/alexnet-tensorflow.ipynb) | [Nbviewer](notebooks/alexnet-tensorflow.slides.html)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-nepal",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's take a look of how does it look like on D2L book!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-mayor",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus Resources\n",
    "\n",
    "- [AutoGluon](https://autogluon.mxnet.io/): easy-to-use AutoML with image, text, or tabular data;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-cream",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- [AutoGluon](https://autogluon.mxnet.io/) enables easy-to-use and easy-to-extend AutoML with a focus on deep learning and real-world applications spanning image, text, or tabular data;\n",
    "\n",
    "- [Deep Graph Libray](https://www.dgl.ai/) develops easy-to-use, high performance and scalable Python package for deep learning on graphs;\n",
    "\n",
    "- [GluonTS](https://gluon-ts.mxnet.io/) supports deep learning based probabilistic time series modeling;\n",
    "\n",
    "- [TVM](https://tvm.apache.org/): automatic generates and optimizes tensor operators on more backend with better performance for CPUs, GPUs and specialized accelerators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-classroom",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [Deep Graph Libray](https://www.dgl.ai/): scalable Python package for graph neural networks (GNNs);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-warner",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [GluonTS](https://gluon-ts.mxnet.io/): deep learning based probabilistic time series;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-paper",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [TVM](https://tvm.apache.org/): automatic optimizes tensor operators on the backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-department",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Q&A \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "If you have any question, please leave us a message at our [discussion forum](https://discuss.d2l.ai/). \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Have fun diving into deep learning!\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "rise": {
   "backimage": "img/d2l_log_as_backimage.png",
   "enable_chalkboard": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
