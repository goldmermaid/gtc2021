{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seeing-congress",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### GTC2021 Tutorial S31692\n",
    "----\n",
    "\n",
    "# Dive into Deep Learning:\n",
    "### Code Side-by-Side with MXNet, PyTorch & TensorFlow\n",
    "\n",
    "Speaker: Rachel Hu (AWS AI)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-clearance",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MXNet, PyTorch or TensorFlow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-redhead",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Deep learning is transforming the world nowadays. Kudos to the continuous advancement of Nvidia powered GPUs and CUDA architecture, parallel model training becomes more realistic and easy to setup. As a result, researchers and practioners may dive deep and focus on model exploration.\n",
    "\n",
    "Around the GPU ecosystem, popular deep learning frameworks with GPU support have been released and iteratively updated. From the earlier version of theano and Caffeine, to now the three most widely used ones: MXNet, PyTorch and TensorFlow. Although these frameworks have similar user interface functionalities, the inherent differences of their designs, architectures, and implementations may lead to a potential variance. You may curious \"what shall I pick for my modeling?\" Well, the answer is \"it depends\"... It may not be a satisfied answer if you may only familiar with one of the three frameworks, and have to struggle to learn the syntacs again for another. But today, I am brining a solution for you to quickly adapt the transformations between all of the 3 frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-ceiling",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"img/mxnet_pytorch_tf_transp.png\" alt=\"Drawing\" style=\"width: 400px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-thanks",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "To fulfill the strong wishes of simpler but more practical deep learning materials, [Dive into Deep Learning](https://d2l.ai/), a unified resource of deep learning was born to achieve the following goals:\n",
    "\n",
    "- Adopt the 3 most popular deep leraning frameworks: MXNet, PyTorch and TensorFlow;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-sigma",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Offer depth theory and runnable code, showing readers how to solve problems in practice;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-sweden",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Allow for rapid updates, both by us, and also by the community at large;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-consent",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Be complemented by a forum for interactive discussions of technical details and to answer questions;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-victoria",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Be freely available for everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-clarity",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-pilot",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### GPU Fundamentals\n",
    "\n",
    "- [Installations with CUDA](https://d2l.ai/chapter_installation/index.html)\n",
    "- [Basic Operations on GPUs](https://nbviewer.jupyter.org/format/slides/github/mli/d2l-1day-notebooks/blob/master/notebooks-2/1-use-gpu.ipynb#/)\n",
    "- [Hardware for deep learning](https://d2l.ai/chapter_computational-performance/hardware.html#gpus-and-other-accelerators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-software",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning Fundamentals\n",
    "\n",
    "Here are a few concepts that will be the prerequistes for this lecture. Take a look if some of them are not familiar to you! :)\n",
    "\n",
    "| title                               |  notes    |  slides    |\n",
    "| ------------------------------ | ---- | ---- |\n",
    "| Data Manipulation with Ndarray | [D2L Book](https://d2l.ai/chapter_preliminaries/ndarray.html) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/mli/d2l-1day-notebooks/blob/master/notebooks-1/1-ndarray.ipynb#/) |\n",
    "| Multilayer Perceptron (MLP) | [D2L Book](https://d2l.ai/chapter_multilayer-perceptrons/mlp.html) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/mli/d2l-1day-notebooks/blob/master/notebooks-1/9-mlp-gluon.ipynb#/) |\n",
    "| Softmax Regression | [D2L Book](https://d2l.ai/chapter_linear-networks/softmax-regression.html) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/mli/d2l-1day-notebooks/blob/master/notebooks-1/7-softmax-regression-gluon.ipynb#/) |\n",
    "| Fundamental of Convolutional Neural Networks | [D2L Book](https://d2l.ai/chapter_convolutional-neural-networks/index.html) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2020/blob/master/Notebooks/convolutions.ipynb) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-kitchen",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Syllabus\n",
    "\n",
    "In this training, we are applying AlexNet directly on Fashion-MNIST dataset, with 3 frameworks side-by-side.\n",
    "\n",
    "| Topics |  |  |\n",
    "| --- | --- | --- |\n",
    "| AlexNet Overview | [D2L Book](https://d2l.ai/chapter_convolutional-modern/alexnet.html#alexnet) | \n",
    "| AlexNet (MXNet) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/Notebooks/Alexnet-mxnet.ipynb) | [Nbviewer](notebooks/alexnet-mxnet.slides.html)|\n",
    "| AlexNet (PyTorch) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/alexnet-torch.ipynb) | [Nbviewer](notebooks/alexnet-torch.slides.html)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-bicycle",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## AlexNet\n",
    "\n",
    "AlexNet, which employed an 8-layer CNN,\n",
    "won the ImageNet Large Scale Visual Recognition Challenge 2012\n",
    "by a phenomenally large margin.\n",
    "This network showed, for the first time,\n",
    "that the features obtained by learning can transcend manually-designed features, breaking the previous paradigm in computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-mobility",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The architectures of AlexNet and LeNet are very similar, as we illustrate below.\n",
    "\n",
    "<center><img src=\"https://d2l.ai/_images/alexnet.svg\" alt=\"Drawing\" style=\"width: 300px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-iraqi",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coding side-by-side\n",
    "\n",
    "| Topics |  |\n",
    "| --- | --- |\n",
    "| AlexNet Overview | [D2L Book](https://d2l.ai/chapter_convolutional-modern/alexnet.html#alexnet) |\n",
    "| AlexNet (MXNet) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/Notebooks/Alexnet-mxnet.ipynb) |\n",
    "| AlexNet (PyTorch) | [Jupyter Notebook](https://nbviewer.jupyter.org/format/slides/github/goldmermaid/gtc2021/blob/master/alexnet-torch.ipynb) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-disability",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus Resources\n",
    "\n",
    "- [AutoGluon](https://autogluon.mxnet.io/) enables easy-to-use and easy-to-extend AutoML with a focus on deep learning and real-world applications spanning image, text, or tabular data;\n",
    "\n",
    "- [Deep Graph Libray](https://www.dgl.ai/) develops easy-to-use, high performance and scalable Python package for deep learning on graphs;\n",
    "\n",
    "- [GluonTS](https://gluon-ts.mxnet.io/) supports deep learning based probabilistic time series modeling;\n",
    "\n",
    "- [TVM](https://tvm.apache.org/): automatic generates and optimizes tensor operators on more backend with better performance for CPUs, GPUs and specialized accelerators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-minnesota",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q&A \n",
    "If you have any question, please leave us a message at our [discussion forum](https://discuss.d2l.ai/). Have fun diving into deep learning!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
